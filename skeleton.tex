% UG project example file, February 2022
%   A minior change in citation, September 2023 [HS]
% Do not change the first two lines of code, except you may delete "logo," if causing problems.
% Understand any problems and seek approval before assuming it's ok to remove ugcheck.
\documentclass[logo,bsc,singlespacing,parskip]{infthesis}
\usepackage{ugcheck}
\usepackage{xcolor}  % Package for colors
\usepackage{listings}
\usepackage{comment}
\usepackage{amsmath}
\usepackage{tcolorbox}
\usepackage{tabularx} % Include this in the preamble
\usepackage{float}

\usepackage{amssymb}
\input{commands.tex}

\lstdefinelanguage{Koka}{
  keywords={fun, return,  var, match, if, then, else, do, with},
  morekeywords=[2]{resume,val, handle, ctl, effect},
  morekeywords=[3]{Sstate, Ready, Blocked, Proc, Nil, Cons},
  sensitive=true,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  morestring=[b]",
}

\lstset{
  language=Koka,
  basicstyle=\scriptsize\ttfamily,
  keywordstyle=\color{purple},          % Group 1: basic syntax
  keywordstyle=[2]\color{blue},         % Group 2: effect-related
  keywordstyle=[3]\color{teal},         % Group 3: data constructors
  commentstyle=\color{gray},
  stringstyle=\color{orange},
  breaklines=true,
  columns=fullflexible,
  showstringspaces=false
}

\tcbset{
  examplebox/.style={
    colback=blue!5!white,
    colframe=blue!75!black,
    boxrule=0.8pt,
    arc=2mm,
    top=1mm,
    bottom=1mm,
    left=1mm,
    right=1mm,
    fonttitle=\bfseries,
    title={Example},
    sharp corners,
  }
}



% Include any packages you need below, but don't include any that change the page
% layout or style of the dissertation. By including the ugcheck package above,
% you should catch most accidental changes of page layout though.

\usepackage{microtype} % recommended, but you can remove if it causes problems
\usepackage{cite} % recommended for citations

\begin{document}
\begin{preliminary}

\title{Implementing Unix using Effect Handlers}

\author{Douglas Torrance}

% CHOOSE YOUR DEGREE a):
% please leave just one of the following un-commented
%\course{Artificial Intelligence}
%\course{Artificial Intelligence and Computer Science}
%\course{Artificial Intelligence and Mathematics}
%\course{Artificial Intelligence and Software Engineering}
%\course{Cognitive Science}
\course{Computer Science}
%\course{Computer Science and Management Science}
%\course{Computer Science and Mathematics}
%\course{Computer Science and Physics}
%\course{Software Engineering}
%\course{Master of Informatics} % MInf students

% CHOOSE YOUR DEGREE b):
% please leave just one of the following un-commented
%\project{MInf Project (Part 1) Report}  % 4th year MInf students
%\project{MInf Project (Part 2) Report}  % 5th year MInf students
\project{4th Year Project Report}        % all other UG4 students


\date{\today}

\abstract{

Algebraic effect provide a structured and modular way to reason about computational effects, such as exceptions, state and concurrency. Most imperative programming languages do not provide a structured method of handling effects, and functional approaches such as Monads lead to poor modularity and composability issues.

Effect handlers have emerged as a flexible, first-class mechanism to define and interpret effects dynamically. It is particularly useful for modelling complex control flows were it has found use in Multicore OCaml. 

Unix was developed in the 1970s at Bell Labs to provide a new approach to operating system design. Prior operating systems were typically monolithic and hardware specific. Unix's was designed to be a small, portable and multi-user operating system which emphasised simplicity, modularity and composability. 
Its key innovations were
\begin{itemize}
    \item Everything is a file - a unified abstraction for devices, processes and data
    \item Pipes and redirection - provides a mechanism to compose commands into programs
    \item Simplified interface - provides a small set of system calls for a consistent way of interacting with; process management, file handling and I/O
\end{itemize}

This dissertation is composed of two parts. The first part implements the "Tiny Unix" system described in Hillerström's "Foundations for Programming and Implementing Effect Handlers". This is written in the Koka programming language to provide a modular and composable implementation of Unix functionality. The second part uses algebraic equivalence rules from Pretnar's "An Introduction to Algebraic Effects and Handlers" to perform reasoning on the implementation, we determine the properties of this implementation and how it compares to standard Unix implementations. 



}

\maketitle

\newenvironment{ethics}
   {\begin{frontenv}{Research Ethics Approval}{\LARGE}}
   {\end{frontenv}\newpage}

\begin{ethics}
This project was planned in accordance with the Informatics Research
Ethics policy. It did not involve any aspects that required approval
from the Informatics Research Ethics committee.

\standarddeclaration
\end{ethics}


\begin{acknowledgements}
Any acknowledgements go here.
\end{acknowledgements}


\tableofcontents
\end{preliminary}


\chapter{Introduction}
\section{Motivation}
Effect handlers are increasingly used to manage computational effects in programming. Unix provides a useful model for exploring their application, as its abstract system calls serve as an interface for programs to interact with the OS, similarly to how effects provide an interface for programs to cause side effects. In this project, we implement these system calls using effect handlers, representing each system call as an algebraic effect. Effect handlers provides us with a simple way of modelling Unix's complicated state and control flow problems, whilst also providing us a way to formally reason about our solutions. This project will show how effect handlers can be used in a practical context to implement features in a composable way. It show cases one of the main advantages to using effect handlers, the ability reason about our code, this is particularly useful for reasoning about complicated control flows. 




\section{Aims}
The objectives of this dissertation are:
\begin{itemize}
    \item Provide back ground for effect handler oriented programming and how it models the Unix philosophy well
    \item Implement the "Tiny Unix" system that Hillertstrom describes in his thesis
    \item Perform algebraic reasoning techniques on the implementation to show it meets the required specifications. 
    
\end{itemize}

\section{Outline}


\chapter{Background}

\section{Algebraic Effects}

Algebraic effects \cite{plotkin_handling_2013} and their handlers \cite{pretnar_introduction_2015} provide a structured approach to managing computational side effects, explicitly denoting effectful computations and handling them non-locally.

We describe an effect by first defining its effect signature, which specifies the operations it can perform along with their input parameters and return types. This signature serves as the interface through which side effects are executed. We then abstract the concept of an effect signature, deferring the implementation details of handling these effects to a later stage. Any function that uses this effect (unless it is responsible for handling it itself) must include the effect in its function signature. 

Effects must ultimately be handled by an effect handler, allowing them to be handled differently based on the scope in which they were raised. When the runtime encounters an effect it searches through successively outer scopes until it finds the appropriate effect handler. This allows the effect to be handled in different ways depending on the scope in which the effect was raised. The effect handler will eventually run the code which carries out the intended side effect. 

Effect handler’s separate the core business logic of the program from the implementation details of handling side effects. This separation prevents side-effect handling logic from being scattered throughout the codebase, thereby improving modularity. 

For example, consider logging data accesses in a database. Typically, logging logic would need to be implemented in every data access function, violating the Single Responsibility Principle, which states a class (or module) should have only one reason to change. However, by using an effect handler, you can define a logging effect and centralize all logging logic in one place. This modular approach allows for easy composition of effectful operations. 

In languages like Java, chaining effectful operations can obscure where effects occur and how errors are handled, making it difficult to reason about the interactions between operations. Effect handlers address this issue, making them particularly useful for implementing side effects such as asynchronous operations, state management, logging, and exception handling. 

In the context of functional programming, effect handlers provide a simple and lightweight method for managing side effects. They serve as a viable alternative to monads, offering a more flexible approach. Unlike monads, which can become rigid once defined, effect handlers allow for greater modification. Additionally, they simplify the combination of multiple side effects, avoiding the complexity of monad transformers. In some cases, effect handlers also offer better performance by eliminating the overhead of repeatedly wrapping and unwrapping values within monadic structures. 

\section{Support for Effect Handlers}

As of the time of writing this paper, effect handlers only have native support in research languages such as Koka and Effect. Some languages have concepts similar to effect handlers, for example the concept of hooks in React are similar to effect handlers in the way they allow you to handle side effects in functional components. 

Features required to have a strong support for effect systems include: 
\begin{itemize}
    \item First class effect handlers
    \item Delimited continuations
    \item Optimisation for nested effects 
    \item Effect Type System. 
    \begin{itemize}
        \item Ability to write custom effect types 
        \item Effect signatures greatly eases reasoning about code and indicates purity vs impurity
        \item Effect type safety and inference
        \item Effect polymorphism


    \end{itemize}
    
\end{itemize}
 
\subsection{Native Support}

\begin{itemize}
    \item Eff \cite{eff_effects}: This language is specifically designed for algebraic effects and effect handlers. It has support for first class effect handlers, delimiting effects and abstract effects
    \item Koka \cite{koka_effects}: This supports effect type inference, strongly distinguishes between pure and impure computations
    \item MultiCore OCaml \cite{ocaml_effects}: An official extension for OCaml which provides effect typing, first class effect handlers and strong pattern matching. integrates well with handling effect cases
\end{itemize}


\subsection{Library Support}
Many languages have their own libraries which attempt to implement effect handlers. These implementations often come with downsides compared to native implementations. Languages which don’t have first class functions which makes it difficult to compose effects. Languages lacking an advanced type system find it difficult to create flexible and reusable handlers. Often languages’ type systems don’t provide type inference and ensure type safety for effects. They are also not optimised to track the multiple layers of context that an effect handler may produce. Despite this, there are some languages with effective third party libraries for using effect handlers.

\begin{itemize}
    \item Haskell \cite{haskell_effects}: The polysemy library provides a strong implementation of effect handlers, including first class effect handlers, effect polymorphism, effect type inference. However its limited support makes it impractical to use so far.
    \item Scala \cite{scala_effects}: The Cats Effect library has good performance and provides effect type polymorphism. However it doesn’t provide first class effect handlers or directly support delimited continuations.
\end{itemize}

\section{Syntax for Effect Handlers}

\subsection{Effect System}
Effect Handler oriented languages have what is known as an effect system \cite{bauer_effect_2013}. This describes the computational effects that may occur when a piece of code is executed. An effect system is typically an extension of a type system. Effect systems can be used to enforce effect safety, ensuring all effects are handled and functions only perform the side effects denotd in their effect signature



\lstset{
backgroundcolor=\color{gray!5}, % Set background color
    basicstyle=\ttfamily,              % Use monospace font
    frame=none,                      % Add a frame around the pseudocode
    numbers=none,                      % No line numbers
    tabsize=4                          % Set tab size
}




\subsection{Effect Type}
An effect type provides an explicit way to denote the side effects that a function performs. Each effect type can have multiple effectful operations. Each effectful operation can have parameters with value types and a valued return type. Note that operations can also produce effects and therefore have effect types.

\begin{lstlisting}
effect exception
    ctl exn(error_msg : string) : a 

fun safe_div (x : int, y: int) : exn int
    if y == 0 then exn("div by zero") else return x/y
\end{lstlisting}

Pure functions use the unit effect type. This shows it has no side effects. 

\begin{lstlisting}
fun add (x: Int, y: int) : () int {
	return x + y
}
\end{lstlisting}

\section{Shallow vs Deep Handlers}

Deep handlers \cite{hillerstrom_foundations_nodate} handlers can handle all the effects caused by a computation. When the continuation is captured in a handler, the captured continuation is also wrapped in the handler. This means that deep handlers can handle effects, which themselves invoke effects. 

In contrast, shallow handlers \cite{ryu_shallow_2018} only manages the first effect caused by a computation. The resumed program no longer includes the handler and the programmer needs to provide a new handler for an effect the resumption may perform.
Deep and Shallow handlers can simulate each others behaviour. However it may make more sense to use one type over another in certain contexts. Most languages only support one or the other. As of 2024 deep handlers are the more popular choice amongst effect oriented languages.

We can think of effects forming a computational tree. Each effect is a node which can have subtrees which represent its continuations. The leaves are return expressions which are pure values. A deep handler for an effect is like a fold over the computational tree which provides an interpretation to each instance of that effect given its leaves and subtrees. Just like a fold the deep handler will recursively handle the current operation, and all of its subtrees (continuations). This makes deep handlers easy to reason about as we can assume the way that the continuation will be interpreted will be consistent and has an algebraic structure.
However a shallow handler does not recurse like this, it is only applied to the first effect it sees. It must be explicitly reapplied to continuations if we want their effects to be interpreted too. This makes it harder to do formal reasoning for but it makes it more flexible control over how you handle effects.


\section{Unix}
Unix is an operating system developed by Bell Labs in the 1970s. Its aim is to create a portable, multi-user, multi-tasking system. It is responsible for managing the:
\begin{itemize}
    \item Processes: creating, managing process communication, terminating processes, forking processes
    \item Scheduling
    \item Basic IO
    \item User and user environment management
\end{itemize}

Unix is built on the “Unix Philosophy” which follows the principles of simplicity and modularity. The “everything is a file” philosophy of Unix provides a consistent interface for us to interact with system resources. This will allow us to separate functionality into modules and implement them using effect handlers.

\section{Evaluating Previous work}
Daniel Hillerström has implemented a theoretical implementation of Unix in his 2021 paper “Foundations for Programming and Implementing Effect Handlers” \cite{hillerstrom_foundations_nodate}. He makes analogy between operating systems and effect handlers that both interpret a series of abstract commands, in the case of the OS this is system calls, in the case of effect handlers, this is operations. The composition of effect handlers, which he views as “tiny operating systems” can provide semantics for a Unix implementation. He uses deep handlers to implement; multiple user sessions, time-sharing and file IO.

This paper will use Koka to create a concrete implementation of the abstract syntax he used in his paper. Then we will implement proof by inductions to show certain properties about effect handlers.

\chapter{Unix Implementation}
Having described the theoretical benefits of effect handlers in the previous chapter, this chapter shows the practical implementation of the "Tiny Unix" system written by Hillerström in the Koka programming language. 

The features we implement provide some great examples of problems which are known to be difficult to model in traditional programming paradigms.  These include dynamic scoping, global state, control flow interruptions and reasoning about suspended computations. 

We will see how Koka allows us to implement each effect independently and then compose them together to express this behaviour cleanly and concisely.
In his thesis, Hillerström uses a pseudo-lambda calculus that can switch between deep and shallow handlers. I only use deep handlers in my Koka implementation.



\section{Process Status}
In Unix, when processes exit they must provide a code. A return code of 0 represents a successful execution and any other number otherwise. In a real Unix system, the specific non-zero number represents the type of error, however we won't implement this level of detail in our system.

We first begin by defining the exit effect with a single exit operation parameterised by an integer.
\begin{lstlisting}
effect exit
  ctl exit(n : int) : a
\end{lstlisting}

We can now write the exit handler:
\begin{lstlisting}
fun status(action : () -> <exit|e> a) : e int
    with final ctl exit(code) code
        action()
        0
\end{lstlisting}
In Hillerström's language we needed to add an absurd function to coerce the valueless return into something that made sense within the language. However, in Koka, we can simply return a value without a resumption. In the case that the function returns without calling an exit(n), we assume that it exited successfully and simply return 0.

\section{Basic IO}
Hillerström first models a simplified form of state. You can see from the effect signature that can label the writes with a file descriptor. However, we don't implement the functionality until later and treat all writes as if they are happening to the same file, which we shall conceptualise and stdout, no matter the file descriptor.

\begin{lstlisting}
effect bio
    fun writeBio( fd : filedesc, s : string ) : ()
\end{lstlisting}

Here we define the handler:

\begin{lstlisting}
fun bio( action : () -> <bio|e> a ) : e (a,string)
  var buf := ""    
  with handler
    return (x) -> (x, buf)
    fun writeBio(fd, s) -> { buf := buf ++ s }
  action()
\end{lstlisting}

Note that unlike in Hillerström's implementation we don't need explicit \texttt{resume} keywords. Effects of type \texttt{fun} just perform an effectful operation and continue execution immediately. 

\section{Users and Environment Variables}
Environment variables are key-value pairs stored in the environment of a process. In this implementation, provide an example by storing the current user's name as an environment variable.

We store the users as type:
\begin{lstlisting}
type user = Root, Alice, Bob
\end{lstlisting}

We define effects su (Switch User) parameterised by the user we wish to switch to and whoami() which returns the current user as a string.
\begin{lstlisting}
effect su
  ctl su( u : user ) : ()

effect whoami
  fun whoami() : string
\end{lstlisting}


\begin{lstlisting}
fun env( user : user, action : () -> <whoami|e> a ) : e a
  with fun whoami() 
    match user
      Root  -> "root"
      Alice -> "alice"
      Bob   -> "bob"
  action()
\end{lstlisting}

Next we define seperate handlers for the \texttt{su} and \texttt{whoami()} effects 
\begin{lstlisting}
fun session-mgr( initial-user : user, action : () -> <su,whoami|e> a ) : e a
  with env(initial-user)
  with ctl su( u : user )
         mask<whoami>
           with env(u)
           resume(())
  action()

fun env( user : user, action : () -> <whoami|e> a ) : e a
  with fun whoami() 
    match user
      Root  -> "root"
      Alice -> "alice"
      Bob   -> "bob"
  action()
\end{lstlisting}

Env is a handler parameterised by the current user, which simply wraps the resumption it is supposed to have scope for, which would represent a process, and returns this value when queried. 

session-mgr manages user switches by wrapping the continuation in a new \texttt{env} handler. This provides greater modularity than global variables as the state is entirely encapsulated by the handler. This is very useful in the next, section which is concerned with process forking.


\subsection*{Interaction With Exit}
This next property is a specialisation of the absorption proof for exceptions shown earlier.


\equivalenceStatement{nondet}
{if Fork() then exit(-1) else $b$}
{nondet}
{-1 ++ (with status handle $b$)}


\textbf{LHS}
\[
\begin{array}{l}
\quad\equiv\quad (11,\; \text{non det}) \\[5pt]
\textbf{resume } \text{True} \;\texttt{++}\; \textbf{resume } \text{False} \; [()/x,\; \text{fun } r \rightarrow \textbf{with status handle } (\textbf{if } r \text{ then exit()} \textbf{ else } b)] \\[5pt]

\quad\equiv\quad (\text{subst}) \\[5pt]
\text{fun } r \rightarrow \textbf{with status handle } (\textbf{if } r \text{ then exit()} \textbf{ else } b)\; \text{True} \\
\texttt{++} \\
\text{fun } r \rightarrow \textbf{with status handle } (\textbf{if } r \text{ then} \text{ exit()} \textbf{ else } b)\; \text{False} \\[5pt]

\quad\equiv\quad (8,\; \text{simplify}) \\[5pt]
\textbf{with status handle } exit(-1) \;\texttt{++}\; \textbf{with status handle } b \\[5pt]

\quad\equiv\quad (11,\; \text{status}) \\[5pt]
x [-1/x,\; \text{fun } x \rightarrow C \;/\; k] \;\texttt{++}\; \textbf{with status handle } b \\[5pt]

\quad\equiv\quad (\text{subst}) \\[5pt]
-1 \;\texttt{++}\; \textbf{with status handle } b
\end{array}
\]


\[
\textbf{LHS = RHS}
\]


\section{Multi-Process System}
\subsection*{Forking}
Hillerstrom describes how forking is a nondeterministic operation as from the perspective of the process making the Fork call. It is unclear in which order the processes will execute as this is managed by the operating system's scheduling policy. 

\begin{lstlisting}
effect fork
  ctl fork() : bool     

fun forking( action : () -> <fork|e> a ) : e list<a>
  with handler
    return(x) [x]
    ctl fork() resume(True) ++ resume(False)
  action()
\end{lstlisting}

We can see that the forking handler introduces two resumptions, splitting computation down two paths. The resumption with True represents the parent and the resumption with False represents the child. We return these resumptions as a list which can be used by the scheduler.

This is designed to be used in code such as:
\begin{lstlisting}
    if fork() {
        // ... parent specific code
    }
    else{
        /// ... child specific code
    }
    
    // code executed by the child and the parent
\end{lstlisting}
This is a simple way of writing code for two programs within the same file.

\subsection*{Scheduling}
Fork has given us the capability to spawn new processes, it returns these as list of paused processes. We must implement a scheduling algorithm to interleave the running of these two processes.

First we must be able to differentiate between a process that has finished and one which is just temporarily paused. We introduce a data type to represent these two process states called \texttt{pstate}. 
\begin{lstlisting}
type pstate<e,a>
  Done(result : a)
  Paused(resumption : () -> e pstate<e,a> )
\end{lstlisting}

Currently there is no way for a process to indicate it is ready to pause, once it is started it will execute until it has finished. We introduce a way of yielding control to the scheduler to allow the interleaving of process execution.

We introduce an effect called `interrupt` and an effect handler called `reify process` which allows us to capture the continuation of a process after it has called interrupt().
\begin{lstlisting}
effect interrupt
  ctl interrupt() : ()

fun reify-process(action : () -> <interrupt|e> a) : e pstate<e,a> 
  with handler  
    return(x) -> Done(x)
    ctl interrupt() -> Paused(fn() resume(()))
  action()
\end{lstlisting}
In our simplified system this must be done manually by the programmer. We could introduce wrapped functions such as \texttt{interrupt-write} however the programmer must be aware that due to non-determinism, these writes may not occur consecutively in the file:
\begin{lstlisting}
interrupt-write("abc");
interrupt-write("def");
\end{lstlisting}


Finally we must introduce a scheduler to coordinate the running of our processes: 
\begin{lstlisting}
fun scheduler( pstates : list<pstate<<fork,div|e>,a>> ) : <div|e> list<a>
  fun schedule( todos : list<pstate<<fork,div|e>,a>>, done : list<a> ) : <div|e> list<a>
    match todos
      Nil -> done
      Cons(Done(x),ps') -> schedule(ps', Cons(x,done))
      Cons(Paused(m),ps') ->
        val ps = forking( m )
        schedule( ps' ++ ps, done )
  schedule(pstates,[])

fun timeshare( action : () -> <fork,interrupt,div|e> a ) : <div|e> list<a>
  val p = Paused( fn() reify-process(action) )
  scheduler([p])
\end{lstlisting}
It maintains two lists of processes, one containing paused processes and one containing finished processes. It works recursively; it runs the first process in the paused until it reaches an interrupt, then it runs the scheduler again with tehe process added to the end of the paused queue. If a process is finished it is added to the done queue. This procedure repeats until there are no processes left in the paused queue.

\section{Serial File System}
Here we implement a more realistic version of the file system we implemented earlier. A unix file system is implemented on top of an array of bytes. Unix structures this medium into several key regions to facilitate file management:
\begin{itemize}
    \item Directory Region: This stores mappings between human-readable filenames and their corresponding Inode numbers.
    \item Inode Region: The Inode list contains meta data about each file
    \item Data Region: This stores the actual contents of file which are accessed via pointers stored in the iNode
\end{itemize}

We define our file system as a record type, composed of the these three lists and two integers to count where the next inode and data regions should be allocated.

\begin{lstlisting}
type directory 
  Directory
    d_list : list<(string, int)>

type dataRegion 
  DataRegion
    dr : list<(int, string)>

type iNode
  INode
    no : int
    loc : int

type iList 
  IList
    il : list<(int, iNode)> 

struct fileSystem
  dir   : directory
  ilist : iList
  dreg  : dataRegion
  dnext : int
  inext : int

\end{lstlisting}

We define the initial file system state \texttt{fs0} as:
\begin{lstlisting}
val fs0 : fileSystem =
  FileSystem (
    Directory([("stdout", 0)]),
    IList([(0, INode ( 1, loc = 0 ))]),
    DataRegion([(0, "")]),
    1,
    1
  )
\end{lstlisting}

\subsection*{File Reading and Writing}

We define effects for reading and writing for our file system. The effect \texttt{read} is parameterised with an iNode number and returns an \texttt{Option<String>} type which indicates success or failure to read from the specified iNode. The \texttt{write} operation takes an integer to denote the iNode and a string to append to the file associated with this iNode. It does not indicate whether or not the write succeeded.

\begin{lstlisting}
effect fileRW
    fun read( ino : int ) : option<string>
    fun write( ino : int, s : string ) : ()
\end{lstlisting}



\begin{lstlisting}
fun fread( ino : int, fs : fileSystem ) : <div,fail|e> string
    val inode = lookupINode(ino, fs.ilist)
    val ret = lookupDataRegion(inode.loc, fs.dreg)
    ret
\end{lstlisting}

The various \texttt{lookup} utility functions must account for the possibility that they could fail. We introduce a \texttt{fail} effect and an associated \texttt{withDefault} handler to 

\begin{lstlisting}
effect fail
  ctl fail() : a

fun withDefault<a>(default: a, m: () -> <div,fail|e>a) : <div|e>a
  with handler
    return(x) -> x
    ctl fail() -> default
  m()
\end{lstlisting}

\begin{lstlisting}
fun fileRW<a>(m: () -> <fileRW,div,state<fileSystem>|e>a) : <state<fileSystem>,div|e>  a {
  with handler
    fun read(ino) {
      val cs = withDefault(None, fn() -> Some(fread(ino, get())))
      cs
    }
    fun write(ino, cs) {
      withDefault((), fn() {
          val fsys  = get()
          val fsys' = fwrite(ino, cs, fsys)
          put(fsys')
          ()
      })
    }
  m()
}
\end{lstlisting}

This is the handler for read and write operations in our system. We wrap \texttt{read} and \texttt{write} operations with \texttt{withDefault} to provide error handling, we make failures in lookup and modify functions correspond to None.

\subsection*{File Creation and Opening}

We define effects for creating and opening files:

\begin{lstlisting}
effect fileCO
  ctl create( fname : string ) : option<int>
  ctl open( fname : string ) : option<int>
\end{lstlisting}

In a real unix system when a process opens a file, they receive a file descriptor that refers to an entry in the open file descriptor table. This is adds an entry to a global 'Open File Table'. The OFT tracks; which files are open, how they are being accessed (read, write), at which offsets they are being accessed. We present a simplified version which means we don't provide shared state management in the same way. There are no restrictions to concurrent reading or writing. Our opening file mechanism simply returns the associated iNode from the file name.

\begin{lstlisting}
fun fopen(fname: string, fs : fileSystem) 
    match fs.dir {
        Directory(d_list) ->
        match d_list {
            Nil        -> fail()  
            Cons((k, v), rest) ->
            if k == fname then v
            else lookupDirectory(fname, Directory(rest))
        }
    }
\end{lstlisting}    


When creating a file we must handle two possibilities:
\begin{itemize}
    \item The file already exists: in this case we must remove the file contents and simply return the associated  iNode and the modified File System.
    \item The file doesn't exist: in this case we must first allocate space in the data region, then allocate an iNode and then add the file name to the directory. It returns the iNode of this file and the modified FileSystem as a tuple.
\end{itemize}

\begin{lstlisting}
fun fcreate(fname: string, fs: fileSystem) : <div,fail> (int, fileSystem) 
  if has(fname, fs.dir) then {
    val ino = fopen(fname, fs)  
    val inode = lookupINode(ino, fs.ilist)  
    val dreg' = modifyDataRegion(inode.loc, "", fs.dreg)  

    (ino, FileSystem(fs.dir, fs.ilist, dreg', fs.dnext, fs.inext))  
  }
  else {
    val loc = fs.dnext  // Get next free data block
    val dreg' = DataRegion(Cons((loc, ""), fs.dreg.dr))  

    val ino = fs.inext  // Get next free i-node index
    val inode = INode(loc, 1)  // Create a new i-node
    val ilist' = IList(Cons((ino, inode) , fs.ilist.il))  

    val dir' = Directory(Cons((fname, ino), fs.dir.d_list))  

    val fs' = FileSystem(dir', ilist', dreg', fs.dnext + 1, fs.inext + 1)  
    (ino, fs')
  }

fun has<a, b>(key: string, xs: directory) : <div> bool
    withDefault(False, fn() {
        val disc = lookupDirectory(key, xs)  
        True  
    })
\end{lstlisting}

Now we can implement the handler for the Create an Open operations.

\begin{lstlisting}
fun fileCreateOpen<a>(action : () -> <fileCO, div, state<fileSystem>|e> a) : <state<fileSystem>,div|e> a
  with handler {
    return(x) -> x
    ctl create(name) {
      val maybeIno = withDefault(None, fn() {
        val fs0 = get()
        val (ino,fs1) = fcreate(name, fs0)
        put(fs1)
        Some(ino)
      })
      resume(maybeIno)
    }

    ctl open(name) {
      val maybeIno = withDefault(None, fn() {
        val fs0 = get()
        val ino = fopen(name, fs0)
        Some(ino)
      })
      resume(maybeIno)}  
  }
  action()
\end{lstlisting}

\subsection*{Stream Redirection}
We define the stream redirection operator \texttt{>} to allow us to redirect output streams from processes to files. This is an essential feature for composing commands, enabling pipelines as it allows us to build pipelines without need for explicit intermediate storage.


\begin{lstlisting}
    //
\end{lstlisting}

\subsection*{File Linking and Unlinking}
We will implement two new operations, linking and unlinking files. There are 2 main types of link in Unix, hard and symbolic. We will implement hard links, this means that multiple file names can point to the same iNode. This allows us to create multiple references to the same underlying file.

\begin{lstlisting}
effect fileLU
  ctl link(src: string, tgt : string) :()
  ctl unlink(tgt : string) :()
\end{lstlisting}


\begin{lstlisting}
fun flink(src : string, dest : string, fs : fileSystem) : <div,fail> fileSystem {
  if has(dest, fs.dir) then
    fail()  // If `dest` exists, fail
  else {
    val ino = lookupDirectory(src, fs.dir)

    val dir' = Directory(Cons((dest, ino), fs.dir.d_list))

    val inode = lookupINode(ino, fs.ilist)

    val inode' = INode(inode.no, inode.loc + 1)

    val ilist' = modifyINode(ino, inode', fs.ilist)

    FileSystem(dir', ilist', fs.dreg, fs.dnext, fs.inext)
  }
}
\end{lstlisting}


\subsection*{Piping}
\begin{lstlisting}
effect produce<b>
  ctl yield(x : b) : ()   

effect consume<b>
  ctl await() : b         

\end{lstlisting}

\subsection*{Process Synchronisation}

In this section we introduce more advanced techniques for process scheduling. The current system is purely non-deterministic, it does not give us any control over how these processes interact. This new scheduler allows us to coordinate processes by controlling the order in which processes are executed, vital for executing tasks which have temporal dependencies. This introduces more invariants and partial ordering.

We begin by defining a new set of effects. We update the forking mechanism \texttt{ufork()} to a return an integer instead of a boolean. The operation is still intended to return twice; it returns the process identifier (PID) to the parent and 0 to the child process. The \texttt{interrupt()} operation is exactly the same as before, invoked to suspend the current process and allow another to run. The \texttt{wait} operation is parametrised with an integer, which represents the process which must complete before the invoking process can continue. The invoking process will be blocked until this happens.
\begin{lstlisting}
effect co
  ctl ufork() : int
  ctl wait(pid: int): ()
  ctl sinterrupt() :()
\end{lstlisting}


Then we define data types. \texttt{proc} represents a reified process i.e. a process that has been captured into a function which can run later. It returns a list of type list<int, a> which represents the PID and results of all the processes created during the execution of this process.  \texttt{pstate}, this represents the internal scheduling state of a single process. It is a sum type composed of two constructors, denoting if a process is Ready or Blocked. The Blocked constructor has an additional field, PID, which is the process identifier of the process that we are waiting on. \texttt{sstate}, this represents the complete state of the scheduler, it keeps track of everything it needs to manage and schedule multiple processes. It stores; a list of processes to execute, a list of completed processes, the currently executing process and pnext which is used to provide new process ids.
\begin{lstlisting}
rec type proc<a>
  Proc
    p: sstate<a> -> list<(int, a)>

type spstate<a>
  Ready
    r : proc<a>
  Blocked 
    pid :int 
    proc:proc<a>

type sstate<a> 
  Sstate     
    q : list<(int, spstate<a>)>
    done  : list<(int,a)>
    pid   : int
    pnext : int
\end{lstlisting}


We first define an auxiliary function which abstracts some of the scheduling logic. This function considers three cases; if the next process is ready, it is run, if the next process is blocked it is sent to the back of the queue, if there are no more processes to run, it returns the list of process results.

\begin{lstlisting}
fun runNext<a>(st: sstate<a> ) : <div,co|e> list<(int,a)> 
  match st.q
    Nil -> st.done
    Cons((bpid, Blocked(pid', proc)), ps) -> 
      val newQ = ps ++ [(bpid, Blocked(pid', proc))]
      
      val newsState =  Sstate (q = newQ, done = st.done, pid = st.pid, pnext = st.pnext)
      runNext(newsState) 
    Cons((rpid, Ready(proc)), ps) -> 
      val newState =  Sstate (q = ps, done = st.done, pid = rpid, pnext = st.pnext)
      val res = proc.p
      res(newState)
\end{lstlisting}

The scheduler is a handler for concurrency effects (\texttt{co} that occur when running the suspended computation comp(). My implementation uses state to keep track of the scheduler state, instead of parameterised handlers in the original Hillerström implementation. 

It handles fork operations by constructing a child process in a Ready state and adding it to the end of the process queue. The Child's resumption is parameterised with 0 so it is aware it is the child process. Finally we parameterise the resumption to the parent with the PID of the child process.

Wait is parameterised by the process it Waits upon. We check the process queue for the process we are waiting for. If it is in the queue then we add this queue in a Blocked state to the end of the process queue. Otherwise we add it in a ready state to the end of the process queue.

Interrupt simply adds the current process to the end of the process queue.

\begin{lstlisting}
fun scheduler<a,e>(comp : () -> <co,div> a, init : sstate<a>) : <div|e> list<(int,a)>
  with handler
    return(x) -> 
      val done'   = Cons((init.pid, x), init.done)
      val newInit = Sstate( q=init.q, done = done', pid = init.pid, pnext= init.pnext)
      runNext(newInit)

    ctl ufork() -> 
      val childProc  = fn(st) ->  resume(0, stChild)  
      val childPid   = init.pnext
      val newQ       =  init.q ++ 
                        [(childPid, Ready(childProc(st)))]
      val st'        = SState (q = newQ, done=init.done, pid=init.pid, pnext = childPid + 1 )
      r(childPid, st')

    ctl sinterrupt() ->
      val interrupted = fn(stInt) -> resume(())
      val newQ        = init.q ++ [(init.pid, Ready(Proc(interrupted)))]
      val _ = runNext(Sstate(q = newQ, done = init.done, pid = init.pid, pnext = init.pnext))
      ()

    ctl wait(pid') ->
      val waitingProc = fn(stWait) -> r((), stWait)
      val newQ =
        if hasPid(pid', init.q)
        then init.q ++ [(init.pid, Blocked(pid', Proc(waitingProc)))]
        else init.q ++ [(init.pid, Ready(Proc(waitingProc)))]
      runNext(Sstate( q = newQ, done = init.done, pid=init.pid,pnext=init.pnext))
      
  comp()
\end{lstlisting}    

\subsection*{Chapter Conclusion}

In this chapter we have shown how effect handler oriented programming provides a clean, modular and composable framework for implementing complex control flow and dynamic scoping problems. Using a Unix-like system as a case study, we demonstrated how features such as file I/O, environment variables, process forking, and scheduling can each be modelled as distinct effects and handled independently. This implementation phase will demonstrate that the same modular handler-based abstractions that aid program design will also support program verification.



\chapter{Reasoning}

In this section we use equational reasoning using algebraic equivalences for deep handlers as defined in Pretnar's Handlers Tutorial \cite{pretnar_introduction_2015}. These are written in figure \ref{fig:equational-laws}.  These equivalences provide a foundation for proving formal properties of Unix programs implemented using effect handlers. If we can apply these rules to transform one computation into another, we can consider them the same up to observational equivalence.
An external observer refers to anything outside the computation itself, including systems like the file system, environment variables, or exception handlers that could observe or be affected by its effects.

Effect handlers make this kind of reasoning possible by making effects explicit and providing a clear separation between where effects are invoked and how they are handled, enabling formal reasoning with algebraic rules.

We will use these equivalences to:
\begin{itemize}
    \item prove that key features of our Unix implementation are correct. 
    \item we will examine interesting properties of these operations, individually and behaviour that arise out of their composition. 
\end{itemize}


\begin{figure}[H]
    \centering
    \begin{tcolorbox}[colframe=black, colback=white, sharp corners]
    \begin{align*}
        &\text{(1) } \quad \text{do } x \leftarrow \text{return } v \; \text{in } c \equiv c[v/x] \\
        &\text{(2) } \quad \text{do } x \leftarrow \text{op}(v; y.\, c_1) \; \text{in } c_2 \equiv \text{op}(v; y.\, \text{do } x \leftarrow c_1 \; \text{in } c_2) \\
        &\text{(3) } \quad \text{do } x \leftarrow c \; \text{in return } x \equiv c \\
        &\text{(4) } \quad \text{do } x_2 \leftarrow (\text{do } x_1 \leftarrow c_1 \; \text{in } c_2) \; \text{in } c_3 \equiv \text{do } x_1 \leftarrow c_1 \; \text{in } (\text{do } x_2 \leftarrow c_2 \; \text{in } c_3) \\
        &\text{(5) } \quad \text{if true then } c_1 \textbf{ else } c_2 \equiv c_1 \\
        &\text{(6) } \quad \text{if false then } c_1 \textbf{ else } c_2 \equiv c_2 \\
        &\text{(7) } \quad \textbf{if } v \textbf{ then } c[\text{true}/x] \textbf{ else } c[\text{false}/x] \equiv c[v/x] \\
        &\text{(8) } \quad (\lambda x \rightarrow c) \; v \equiv c[v/x] \\
        &\text{(9) } \quad \lambda x \rightarrow v \; x \equiv v 
    \end{align*}
    \end{tcolorbox}
    
    \begin{tcolorbox}[colframe=black, colback=white, sharp corners]
    \begin{align*}
        &\text{(10) } \quad \text{with } h \; \text{handle } (\text{return } v) \equiv c_r[v/x] \\
        &\text{(11) } \quad \text{with } h \; \text{handle } (\text{op}_i(v; y.\, c)) \equiv c_i[v/x, (\lambda y \rightarrow \text{with } h \; \text{handle } c)/k]  (1 \leq i \leq n) \\
        &\text{(12) } \quad \text{with } h \; \text{handle } (\text{op}(v; y.\, c)) \equiv \text{op}(v; y.\, \text{with } h \; \text{handle } c) \quad (\text{op} \notin \{\text{op}_i\}_{1 \leq i \leq n}) \\
        &\text{(13) } \quad \text{with } (\text{handler} \{\text{return } x \rightarrow c_2\}) \; \text{handle } c_1 \equiv \text{do } x \leftarrow c_1 \; \text{in } c_2
    \end{align*}
    \end{tcolorbox}

    \caption{Pretnar's Algebraic Equivalences}
    \label{fig:equational-laws}
\end{figure}







\section{Simplified State Proofs}
\subsection{Single Cell State}
\label{subsec:simplified-state}
We begin by reasoning about a minimal model of state, consisting of a single global cell and get and set operations. These handlers were taken from Pretnar's Handler Tutorial \cite{pretnar_introduction_2015}. Although this model is deliberately simple, the reasoning principles it demonstrates are general. We will see that the same basic properties of state we prove here arise in more complex examples later on.

\handlerDef{state}{
    &\text{get}(\_, k) \mapsto \text{fun s} \rightarrow (k\ s)\ s \\
    &\text{set}(s, k) \mapsto \text{fun } \_ \rightarrow (k\ () )\ s \\
    &\text{return}\ x \mapsto \text{fun } \_ \rightarrow \text{return } x 
}

We use this handler to prove four basic state properties. These proofs are the minimum set needed to capture the basic behaviour of state, as they allow us to reason about any sequence of get and sets.

\subsubsection*{Idempotence of Set}
The last set overwrites the first one:
\[
\begin{aligned}
    &\mathsf{\textbf{with}} \; \mathsf{state} \; \mathsf{\textbf{handle}} \\
    &\quad \operatorname{set} \; a \; (x. \operatorname{set} \; b \; (y. C)) \\
    &\equiv \\
    &\mathsf{\textbf{with}} \; \mathsf{state} \; \mathsf{\textbf{handle}} \\
    &\quad \operatorname{set} \; b \; (y. C)
\end{aligned}
\]

\underline{Left Hand Side}

\[ 
\begin{array}{l}
\quad\equiv\quad (11) \\[5pt]
\text{fun }\_ \rightarrow (k\ ())\ s\ [a/s,\ \text{fun } x \rightarrow \text{\textbf{with} state \textbf{handle} } set(b)(y.C)/k] \\[5pt]
\quad\equiv\quad (\text{subst}) \\[5pt]
\text{fun }\_ \rightarrow ((\text{fun } x \rightarrow \text{\textbf{with} state \textbf{handle} } set(b)(y.C))\ ())\ a \\[5pt]
\quad\equiv\quad (8) \\[5pt]
\text{fun }\_ \rightarrow (\text{\textbf{with} state \textbf{handle} } set(b)(y.C))\ a \\[5pt]
\quad\equiv\quad (11) \\[5pt]
\text{fun }\_ \rightarrow (\text{fun }\_ \rightarrow (k\ ())\ s\ [b/s, \text{fun } y \rightarrow \text{\textbf{with} state \textbf{handle} } C/k])\ a \\[5pt]
\quad\equiv\quad (\text{subst}) \\[5pt]
\text{fun }\_ \rightarrow (\text{fun }\_ \rightarrow (\text{fun } y \rightarrow \text{\textbf{with} state \textbf{handle} } C)\ ())\ b)\ a \\[5pt]
\quad\equiv\quad (8) \\[5pt]
\text{fun }\_ \rightarrow (\text{fun }\_ \rightarrow (\text{\textbf{with} state \textbf{handle} } C)\ b)\ a \\[5pt]
\quad\equiv\quad (\text{application}) \\[5pt]
\text{fun }\_ \rightarrow (\text{\textbf{with} state \textbf{handle} } C)\ b
\end{array}
\]

\underline{Right Hand Side}
\[ 
\begin{array}{l}
\quad\equiv\quad (11) \\[5pt]
\text{fun }\_ \rightarrow (k\ ())\ s\ [b/s, \text{fun } y \rightarrow \text{\textbf{with} state \textbf{handle} } C/k] \\[5pt]
\quad\equiv\quad (\text{subst}) \\[5pt]
\text{fun }\_ \rightarrow ((\text{fun } y \rightarrow \text{\textbf{with} state \textbf{handle} } C)\ ())\ b \\[5pt]
\quad\equiv\quad (8) \\[5pt]
\text{fun }\_ \rightarrow (\text{\textbf{with} state \textbf{handle} } C)\ b
\end{array}
\]

LHS $\equiv$ RHS

\subsubsection*{Idempotence of Get}
Reading the state twice in a row gives the same result as reading it once.


\[
\begin{aligned}
    &\mathsf{\textbf{with}} \; \mathsf{state} \; \mathsf{\textbf{handle}} \\
    &\quad \operatorname{get}() \left( \mathsf{x.get}() \left( y.C \right) \right) \\
    &\equiv \\
    &\mathsf{\textbf{with}} \; \mathsf{state} \; \mathsf{\textbf{handle}} \\
    &\quad \operatorname{get}() \left( x.C[x/y] \right)
\end{aligned}
\]
\underline{Left Hand Side}

\[ 
\begin{array}{l}
\quad\equiv\quad (11) \\[5pt]
\text{fun } s \rightarrow (k\ s)\ s\ [()/v, \text{fun } x \rightarrow \text{\textbf{with} state \textbf{handle} } get()(y.C)/k] \\[5pt]
\quad\equiv\quad (\text{subst}) \\[5pt]
\text{fun } s \rightarrow ((\text{fun } x \rightarrow \text{\textbf{with} state \textbf{handle} } get()(y.C))\ s)\ s \\[5pt]
\quad\equiv\quad (8) \\[5pt]
\text{fun } s \rightarrow (\text{\textbf{with} state \textbf{handle} } get()(y.C[s/x]))\ s \\[5pt]
\quad\equiv\quad (11) \\[5pt]
\text{fun } s \rightarrow ((\text{fun } s'\rightarrow (k\ s')\ s')\ [()/v, \text{fun } y\rightarrow \text{\textbf{with} state \textbf{handle}}/k])\ s \\[5pt]
\quad\equiv\quad (\text{subst}) \\[5pt]
\text{fun } s \rightarrow ((\text{fun } s' \rightarrow (( \text{fun } y \rightarrow \text{\textbf{with} state \textbf{handle} } C[s/x])\ s')\ s')\ s \\[5pt]
\quad\equiv\quad (8) \\[5pt]
\text{fun } s \rightarrow (\text{fun } s' \rightarrow (\text{\textbf{with} state \textbf{handle} } C[s/x][s'/y]s')) \\[5pt]
\quad\equiv\quad (8) \\[5pt]
\text{fun } s \rightarrow (\text{\textbf{with} state \textbf{handle} } C[s/x][s/y])\ s
\end{array}
\]



\underline{Right Hand Side}

\[ 
\begin{array}{l}
\quad\equiv\quad (11) \\[5pt]
\text{fun } s \rightarrow (k\ s)\ s\ [()/v, C[x/y]] \\[5pt]
\quad\equiv\quad (\text{subst}) \\[5pt]
\text{fun } s \rightarrow ((\text{fun } x \rightarrow \text{\textbf{with} state \textbf{handle} } C[x/y])) \\[5pt]
\quad\equiv\quad (8) \\[5pt]
\text{fun } s \rightarrow (\text{\textbf{with} state \textbf{handle} } C[x/y][s/x])\ s
\end{array}
\]

LHS $\equiv$ RHS



\subsubsection*{Get-After-Set}
Reading the state immediately after setting it returns the new value.
\[
\begin{aligned}
    &\mathsf{\textbf{with}} \; \mathsf{state} \; \mathsf{\textbf{handle}} \\
    &\quad \operatorname{set} \; a \; (x. \operatorname{get}() \; (y. C)) \\
    &\equiv \\
    &\mathsf{\textbf{with}} \; \mathsf{state} \; \mathsf{\textbf{handle}} \\
    &\quad \operatorname{set} \; a \; (x. C[a/x])
\end{aligned}
\]

\underline{Left Hand Side}
\[ 
\begin{array}{l}
\quad\equiv\quad (11) \\[5pt]
\text{fun }\_ \rightarrow (k\ ())\ s\ [a/s, \text{fun } x \rightarrow \text{\textbf{with} state \textbf{handle} } get() (y. C)/k] \\[5pt]
\quad\equiv\quad (\text{subst}) \\[5pt]
\text{fun }\_ \rightarrow ((\text{fun } x \rightarrow \text{\textbf{with} state \textbf{handle} } get() (y. C)) ())\ a \\[5pt]
\quad\equiv\quad (8) \\[5pt]
\text{fun }\_ \rightarrow (\text{\textbf{with} state \textbf{handle} } get() (y. C))\ a \\[5pt]
\quad\equiv\quad (11) \\[5pt]
\text{fun }\_ \rightarrow (\text{fun } s' \rightarrow  (k\ s')\ s' [()/s, \text{fun } y \rightarrow \text{\textbf{with} state \textbf{handle} } C / k])\ a \\[5pt]
\quad\equiv\quad (\text{subst}) \\[5pt]
\text{fun }\_ \rightarrow ((\text{fun } s' \rightarrow ((\text{fun } y \rightarrow \text{\textbf{with} state \textbf{handle} } C)\ s' )\ s')\ a \\[5pt]
\quad\equiv\quad (\text{application}) \\[5pt]
\text{fun }\_ \rightarrow ((\text{fun } y \rightarrow \text{\textbf{with} state \textbf{handle} } C)\ a )\ a \\[5pt]
\quad\equiv\quad (8) \\[5pt]
\text{fun }\_ \rightarrow (\text{\textbf{with} state \textbf{handle} } C[a/y])\ a
\end{array}
\]

\underline{Right Hand Side}
\[ 
\begin{array}{l}
\quad\equiv\quad (11) \\[5pt]
\text{fun }\_ \rightarrow (k\ ())\ s\ [a/s, \text{fun } x \rightarrow \text{\textbf{with} state \textbf{handle} } C[a/y]/k] \\[5pt]
\quad\equiv\quad (\text{subst}) \\[5pt]
\text{fun }\_ \rightarrow ((\text{fun } x \rightarrow \text{\textbf{with} state \textbf{handle} } C[a/y]) ())\ a \\[5pt]
\quad\equiv\quad (8) \\[5pt]
\text{fun }\_ \rightarrow (\text{\textbf{with} state \textbf{handle} } C[a/y])\ a
\end{array}
\]



\subsubsection*{Set-After-Get}

\[
\begin{aligned}
    &\mathsf{\textbf{with}} \; \mathsf{state} \; \mathsf{\textbf{handle}} \\
    &\quad \operatorname{get}() \left( x. \operatorname{set} \; a \; (y. C) \right) \\
    &\equiv \\
    &\mathsf{\textbf{with}} \; \mathsf{state} \; \mathsf{\textbf{handle}} \\
    &\quad \operatorname{set} \; a \; (y. C[s/x])
\end{aligned}
\]

\underline{Left Hand Side}
\[ 
\begin{array}{l}
\quad\equiv\quad (11) \\[5pt]
\text{fun } s \rightarrow (k\ s)\ s\ [()/v, \text{fun } x \rightarrow \text{\textbf{with} state \textbf{handle} } set(a)(y.C)/k] \\[5pt]
\quad\equiv\quad (\text{subst}) \\[5pt]
\text{fun } s \rightarrow ((\text{fun } x \rightarrow \text{\textbf{with} state \textbf{handle} } set(a)(y.C))\ s)\ s \\[5pt]
\quad\equiv\quad (8) \\[5pt]
\text{fun } s \rightarrow (\text{\textbf{with} state \textbf{handle} } set(a)(y.C[s/x]))\ s \\[5pt]
\quad\equiv\quad (11) \\[5pt]
\text{fun } s \rightarrow ((\text{fun } \_ \rightarrow (k\ ())\ s')[a/s', \text{fun } y \rightarrow \text{\textbf{with} state \textbf{handle} } C[s/x]/k])\ s' \\[5pt]
\quad\equiv\quad (\text{subst}) \\[5pt]
\text{fun } s \rightarrow (\text{fun } \_ \rightarrow (\text{\textbf{with} state \textbf{handle} } C[s/x]) ())\ a \\[5pt]
\quad\equiv\quad (8) \\[5pt]
\text{fun } s \rightarrow (\text{\textbf{with} state \textbf{handle} } C[s/x])\ a
\end{array}
\]


\underline{Right Hand Side}
\[ 
\begin{array}{l}
\quad\equiv\quad (11) \\[5pt]
\text{fun }\_ \rightarrow (k\ ())\ s\ [a/s, \text{fun } y \rightarrow \text{\textbf{with} state \textbf{handle} } C[s/x]/k] \\[5pt]
\quad\equiv\quad (\text{subst}) \\[5pt]
\text{fun }\_ \rightarrow (\text{fun } y \rightarrow \text{\textbf{with} state \textbf{handle} } C[s/x]) ()\ a \\[5pt]
\quad\equiv\quad (8) \\[5pt]
\text{fun }\_ \rightarrow (\text{\textbf{with} state \textbf{handle} } C[s/x]\ a)
\end{array}
\]
LHS $\equiv$ RHS

\subsection{Multi-Cell State}
We can easily generalise this to a multicell example using a map data structure: 

\[
\text{multiState} \ \overset{\text{def}}{\equiv} \ \text{handler} \left\{
\begin{array}{ll}
\text{get}(k_0; k) &\mapsto \text{fun } s \mapsto \text{let } v = \text{lookup}(k_0, s) \text{ in } (k\ v)\ s \\
\text{set}(k_0, v; k) &\mapsto \text{fun } s \mapsto \text{let s'} = \text{update}([k_0 := v],\ s) \text{ in } (k\ ())\ s'\ \\
\text{return } x &\mapsto \text{fun } \_ \mapsto \text{return } x
\end{array}
\right\}
\]

This gives us an additional property, the commutativity of operations on disjoint keys. To prove this we need to show the following properties hold:
\begin{enumerate}
    \item Disjoint Write-Write Commutativity
    \[set(k1,v1);set(k2,v2) \equiv set(k2,v2);set(k1,v1)\] 
    \item Disjoint Write-Read Independence
        \[set(k1,v1);get(k2) \equiv get(k2);set(k1,v1)\] 

    \item Disjoint Read-Read Commutativity
        \[get(k1);get(k2) \equiv get(k2);get(k1)\] 

\end{enumerate}



\section{Process Forking}
Process forking introduces a number of interesting properties for us to consider. Establishing these properties when it is alone provides a base for us to reason about how it interacts upon composition. Then we will go on to analyse how they compose with other handlers. We will see that Forking breaks many of the algebraic properties that previously held in sequential contexts.

When a process forks it introduces two suspended resumptions. As the scheduler determines the execution order, from the perspective of a single process, the system appears non-deterministic; it cannot know when or how other processes will affect the overall state of the system.


\subsection*{Associativity}
Associativity is a fundamental algebraic property that states the grouping of operations in an expression will not change the final result: 
\[
(A \oplus B) \oplus C \quad \equiv \quad A \oplus (B \oplus C)
\]
In this context, the order in which fork operations are grouped does not matter, the observable behaviour, i.e. the set of possible executions remains the same. This means that the following code is equivalent:
\begin{table}[h]
\centering
\begin{tabular}{p{0.45\textwidth} c p{0.45\textwidth}}
\begin{lstlisting}
if Fork(){
    if Fork(){
        A
    }
    else{
        B
    }
}
else{
    C
}
\end{lstlisting}
&
&
\begin{lstlisting}
if Fork(){
    A
} 
else{
    if Fork(){
        B
    }
    else{
        C
    }
}
\end{lstlisting}
\end{tabular}
\end{table}
\vspace{-2em}

This is an important property to prove for parallel programming purposes. It allows us as programmers to rearrange or simplify complex nesting structures. This can make it clearer where we can introduce interrupts to allow for tree-based parallelism.
For example, if we knew that workers were indepedent of each other, restructuring the following code:

\vspace{-1em} % reduce space above table
\begin{table}[h]
\centering
\begin{tabular}{p{0.45\textwidth} c p{0.45\textwidth}}
\begin{lstlisting}
Server forks Worker 1
    Worker 1 forks Worker 2
        Worker 2 forks Worker 3
\end{lstlisting}
&
&
\begin{lstlisting}
Server forks Worker 1
Server forks Worker 2
Server forks Worker 3
\end{lstlisting}
\end{tabular}
\end{table}
\vspace{-1em} % reduce space below table
could allow us to see more easily where we could place interrupts to allow for parallelisation.




\underline{Proof}

In the continuation passing style, we can write the associativity property of \texttt{nondet} as:
\equivalenceStatement{nondet}
{
if Fork() then
if Fork() 
a 
else 
b 
else 
c
}
{nondet}
{
if Fork() then a 
else 
if Fork() 
 then b 
 else c
}

\underline{Left Hand Side}
\[
\begin{array}{l}
\quad \equiv \quad (11) \\[5pt]
\textbf{resume }\text{True} \;\texttt{++}\; \textbf{resume } \text{False} \; [()/x,\; \text{fun } r \rightarrow \textbf{with } \text{nondet handle } (\textbf{if } r \textbf{ then } a \\ \text{ else Fork()}(s \rightarrow \textbf{if }  s \textbf{ then } b \textbf{ else } c)) \;/\; k] \\[5pt]

\quad \equiv \quad (\text{subst}) \\[5pt]
\text{fun } r \rightarrow \textbf{with } \text{nondet handle } (\textbf{if } r \textbf{ then } a \text{ else Fork()}(s \rightarrow \textbf{if } s \textbf{ then } b \textbf{ else } c)) \;\text{True} \\[2pt]
\texttt{++} \\ 
\text{fun } r \rightarrow \textbf{with } \text{nondet handle } (\textbf{if } r \textbf{ then } a \text{ else Fork()}(s \rightarrow \textbf{if } s \textbf{ then } b \textbf{ else } c)) \;\text{False} \\[5pt]

\quad \equiv \quad (8,\; \text{evaluate}) \\[5pt]
\textbf{with } \text{nondet handle } a \;\texttt{++}\; \textbf{with } \text{nondet handle } \text{Fork()}(s \rightarrow \textbf{if } s \textbf{ then } b \textbf{ else } c) \\[5pt]

\quad \equiv \quad (11) \\[5pt]
a \;\texttt{++}\; (\text{resume True} \;\texttt{++}\; \text{resume False} \; [()/x,\; \text{fun } s \rightarrow \textbf{if } s \textbf{ then } b \textbf{ else } c \;/\; k]) \\[5pt]

\quad \equiv \quad (\text{subst}) \\[5pt]
a \;\texttt{++}\; (\text{fun } s \rightarrow \textbf{if } s \textbf{ then } b \textbf{ else } c) \;\text{True} \\
\texttt{++} \\
(\text{fun } s \rightarrow \textbf{if } s \textbf{ then } b \textbf{ else } c) \;\text{False} \\[5pt]

\quad \equiv \quad (8,\; \text{evaluate}) \\[5pt]
a \;\texttt{++}\; (b \;\texttt{++}\; c)
\end{array}
\]


\underline{Right Hand Side}



\[
\begin{array}{l}
\quad \equiv \quad (11) \\[5pt]
\textbf{resume } \text{True} \;\texttt{++}\; \textbf{resume } \text{False} \; [()/x,\; \text{fun } r \rightarrow \textbf{with } \text{nondet handle } (\textbf{if } r \text{ then Fork()} \\(s \rightarrow \textbf{if } s \textbf{ then } a \textbf{ else } b) \textbf{ else } c) \;/\; k] \\[5pt]

\quad \equiv \quad (\text{subst}) \\[5pt]
\text{fun } r \rightarrow \textbf{with } \text{nondet handle } (\textbf{if } r \text{ then Fork()}(s \rightarrow \textbf{if } s \textbf{ then } a \textbf{ else } b) \textbf{ else } c) \;\text{True} \\
\texttt{++} \\
\text{fun } r \rightarrow \textbf{with } \text{nondet handle } (\textbf{if } r \text{ then Fork()}(s \rightarrow \textbf{if } s \textbf{ then } a \textbf{ else } b) \textbf{ else } c) \;\text{False} \\[5pt]

\quad \equiv \quad (8,\; \text{evaluate}) \\[5pt]
\textbf{with } \text{nondet handle } \text{Fork()}(s \rightarrow \textbf{if } s \textbf{ then } a \textbf{ else } b) \;\texttt{++}\; \textbf{with } \text{nondet handle } c \\[5pt]

\quad \equiv \quad (11) \\[5pt]
(\textbf{resume } \text{True} \;\texttt{++}\; \textbf{resume } \text{False} \; [()/x,\; \text{fun } s \rightarrow \textbf{if } s \textbf{ then } a \textbf{ else } b \;/\; k]) \;\texttt{++}\; c \\[5pt]

\quad \equiv \quad (\text{subst}) \\[5pt]
(\text{fun } s \rightarrow \textbf{if } s \textbf{ then } a \textbf{ else } b)\; \text{True} \;\texttt{++}\; (\text{fun } s \rightarrow \textbf{if } s \textbf{ then } a \textbf{ else } b)\; \text{False} \;\texttt{++}\; c \\[5pt]

\quad \equiv \quad (8,\; \text{evaluate}) \\[5pt]
(\text{fun } s \rightarrow \textbf{if } s \textbf{ then } a \textbf{ else } b)\; \text{True} \;\texttt{++}\; (\text{fun } s \rightarrow \textbf{if } s \textbf{ then } a \textbf{ else } b)\; \text{False} \;\texttt{++}\; c \\[5pt]

\quad \equiv \quad (\text{evaluate}) \\[5pt]
(a \;\texttt{++}\; b) \;\texttt{++}\; c
\end{array}
\]


\[
\textbf{LHS} = \textbf{RHS} \quad \text{and} \quad a ++ (b ++ c) \equiv (a ++ b) ++ c
\]


\subsection*{Distributivity}
Distributivity describes how two binary operation interact with one another. Formally, given three elements A,B,C and two binary operations $\diamond, \circ $

\[
\begin{array}{l l}
\text{Left Distributivity:} & A \diamond (B \circ C) \;\equiv\; (A \diamond B) \circ (A \diamond C) \\[5pt]
\text{Right Distributivity:} &(A \diamond B) \circ C  \;\equiv\; (A \circ C) \diamond (B \circ C)
\end{array}
\]



\subsubsection*{Right Distributivity}
We can show that non determinism and sequencing (considered a binary operation \texttt{P;Q}) are right distributive within our system. 
We can prove that the code:

\begin{table}[H]
\centering
\begin{tabular}{p{0.45\textwidth} c p{0.45\textwidth}}
\begin{lstlisting}
if Fork(){
    P; 
    R;
}
else{ 
    Q; 
    R;
}
\end{lstlisting}
&
&
\begin{lstlisting}
if Fork(){ 
    P;
}
else{
    Q;
}
R;
\end{lstlisting}
\end{tabular}
\end{table}

\vspace{-2em}

\underline{Proof}
Expressing this property in the continuation passing style of our equivalence rules:

\equivalenceStatement{nondet}{Fork()(t.(if t then P;R else Q;R) 
}{nondet}{Fork()(t.(if t then P else Q); R)
}

\underline{Left Hand Side}
\[
\begin{array}{l}

\quad\equiv\quad (11) \\[5pt]
\text{resume True} ++ \text{resume False} [()/x, \text{fun } t \rightarrow (\textbf{if } t \textbf{ then } P;R \textbf{ else } Q;R)/k] \\[5pt]
\quad\equiv\quad (\text{subst}) \\[5pt]
\text{fun } t \rightarrow (\textbf{if } t \textbf{ then } P;R \textbf{ else } Q;R)\ \text{True} \\[2pt]
 \mathbin{++} 
\text{fun } t \rightarrow (\textbf{if } t \textbf{ then } P;R \textbf{ else } Q;R)\ \text{False} \\[5pt]
\quad\equiv\quad (8, \text{simplify}) \\[5pt]
P;R  ++ Q;R \\[1em]
\end{array}
\]

\underline{Right Hand Side}
\[
\begin{array}{l}
\quad\equiv\quad (11) \\[5pt]
\text{resume True} ++ \text{resume False} [()/x, \text{fun } t \rightarrow (\textbf{if } t \textbf{ then } P \textbf{ else } Q;R) / k] \\[5pt]
\quad\equiv\quad (\text{subst}) \\[5pt]
\text{fun } t \rightarrow (\textbf{if } t \textbf{ then } P \textbf{ else } Q);R\ \text{True} \\[2pt]
\quad \mathbin{++} \\
\text{fun } t \rightarrow (\textbf{if } t \textbf{ then } P \textbf{ else } Q);R\ \text{False} \\[5pt]
\quad\equiv\quad (8, \text{simplify}) \\[5pt]
(P;R) \: \text{++} \:(Q;R) \\[5pt]
\end{array}
\]


\subsubsection*{Left Distributivity}

Unfortunately, process forking is not, in general, left distributive:

\vspace{-2em}
\begin{table}[H]
\centering
\begin{tabular}{p{0.45\textwidth} c p{0.45\textwidth}}
\begin{lstlisting}
R;
if Fork(){
    P
}
else {
    Q
}
\end{lstlisting}
&
&
\begin{lstlisting}
if Fork(){
    R; 
    P;
} 
else{
    R; 
    Q; 
}
\end{lstlisting}
\end{tabular}
\end{table}
\vspace{-2em}
This is because in the first example R is only executed once by the unforked process, whereas in the second example it is executed by both the parent and the child. 
Mutation operations such as append(x) would be applied a different numbers of times breaking the equivalence.





\section{State Models and Handler Composition}
In the previous section we demonstrated algebraic reasoning about state in a simplified purely sequential setting. In this section introduce nondeterminism via process forking, introducing concurrent executions. 
The order of composition of the state and nondeterminism handlers, significantly impacts the semantics of stateful computations. 

We obtain two different models of state depending on this ordering:
\begin{itemize}
    \item Local State (outer nondeterminism, inner state): Here each nondeterministic branch maintains its own independent state, akin to local variables within a program. The scope is private to the process and only lasts as long as the process lasts.
    \item Global State (outer state, inner nondeterminism): Here the same state is shared among all branches of a nondeterministic computation similar to the case of a global file system.
\end{itemize}







\subsection{Global State : Unix Specifications}
\subsubsection*{Shared State} 
The global state model features a single shared state accessible and modifiable by all branches.

\begin{tcolorbox}[colback=gray!10, colframe=gray!60, sharp corners, boxrule=0.5pt, title={POSIX Base Specifications, Issue 7, p.2316}]
 This volume of POSIX.1-2008 does not specify the behaviour of concurrent writes to a regular file |
 from multiple threads, except that each write is atomic (see Section 2.9.7, onpage 522). |
 Applications should use some form of concurrency control.
\end{tcolorbox}





\[
\begin{array}{l}
\textbf{with } state \textbf{ handle} \\
\quad\textbf{with } nondet \textbf{ handle} \\
\quad\quad \text{Fork()(p.if p then set(x)(a.C\textsubscript{1}) else set(y)(b.C\textsubscript{2}))}
\\
\quad\equiv\quad (11) \quad \\ 
\textbf{with } state \textbf{ handle} \\
 
\quad\textbf{resume } \text{x} \text{ ++ } \textbf{resume } \text{y} \\[2pt]
[()/v, \text{fun } r \rightarrow \text{\textbf{with} nondet \textbf{handle} if } r \text{ then set(x)}(a.C1) \text{ else set(y)}(b.C2)] \\[5pt]
\quad\equiv\quad (\text{subst}) \\[5pt] 
\textbf{with } state \textbf{ handle} \\
\quad
\quad\text{fun } p \rightarrow \text{\textbf{with} nondet \textbf{handle} if } r \text{ then set(x)}(a.C1) \text{ else set()}(b.C2)\ \text{x} \\[2pt]
\quad \quad \text{ ++ } \\[2pt]
\quad \quad \text{fun } p \rightarrow \text{\textbf{with} nondet \textbf{handle} if } r \text{ then set(x)}(a.C1) \text{ else set()}(b.C2)\ \text{y} \\[5pt]
\quad\equiv\quad (8, \text{simplify}) \\[5pt]
\textbf{with } state \textbf{ handle} \\
  
\quad \text{\textbf{with} nondet \textbf{handle} set(x)}(a.C1) \\[2pt]
\quad\text{ ++ } \\ 
\quad\text{\textbf{with} nondet \textbf{handle} set()}(b.C2) \\[5pt]
\quad\equiv\quad (12) \\[5pt]

\textbf{with } state \textbf{ handle} \\
\quad \text{set(x)}(a.\text{\textbf{with} nondet \textbf{handle} } C1) 
\quad \\[2pt]
\quad \text{ ++ } \\ 
\quad \text{set(y)}(b.\text{\textbf{with} nondet \textbf{handle} } C2) \\[5pt]
 
\end{array}
\]

This creates a non deterministic outcome, as we can see from the example above, the order in which we choose to 

\subsection{Local State : Unix Specifications}

\subsubsection{Independent State (isolation):} 
Each branch maintains a separate independent state. This isolation ensures that there is no interference between parallel computations.



\begin{tcolorbox}[colback=gray!10, colframe=gray!60, sharp corners, boxrule=0.5pt, title={POSIX Base Specifications, Issue 7, p.899}]
    Any modifications to the data in
 MAP\_PRIVATE mappings made by the parent after fork() returns shall be visible only to
 the parent. Modifications to the data in MAP\_PRIVATE mappings made by the child shall
 be visible only to the child.
\end{tcolorbox}



\[ 
\begin{array}{l}
\textbf{with } nondet \textbf{ handle} \\
\quad\textbf{with } state \textbf{ handle} \\
\quad\quad \text{Fork()(p.if p then set(x)(a.C\textsubscript{1}) else set(y)(b.C\textsubscript{2}))}
\\
\quad\equiv\quad (12) \\[5pt]
\text{\textbf{with} nondet \textbf{handle}}\ \\ \quad \text{Fork()}(a.\ \text{\textbf{with} state \textbf{handle} } (\textbf{if } a \text{ then set(x)}(b.C\textsubscript{1}) \text{ else set(y)}(d.C\textsubscript{2}))) \\[5pt]
\quad\equiv\quad (11) \\[5pt]
\text{\textbf{resume} x} \text{ ++ } \text{\textbf{resume} y} 
\\ 
\ [()/v, \text{fun } a \rightarrow  \text{\textbf{with} nondet,  state \textbf{handle} if } a \text{ then set(x)}(b.C\textsubscript{1}) \text{ else set(y)}(d.C\textsubscript{2})]
\\ \quad\equiv\quad (\text{subst}) \\[5pt]
\text{fun } a \rightarrow \text{\textbf{with} nondet, state} \textbf{ handle} \text{ if } a \text{ then set(x)}(b.C\textsubscript{1} \text{ else set(y)}(d.C\textsubscript{1}\ \text{x} \\
\text{++} \\
\text{fun } a \rightarrow \text{\textbf{with} nondet, state \textbf{handle} if } a \text{ then set(x)}(b.C\textsubscript{1}) \text{ else set(y)}(d.C\textsubscript{2})\ \text{y} \\[5pt]
\quad\equiv\quad (8, \text{simplify}) \\[5pt]
\text{\textbf{with} nondet, state \textbf{handle} set(x)}(b.C\textsubscript{1})) \\[2pt]
\text{++} \\  \text{\textbf{with} nondet, state \textbf{handle} set(y)}(d.C\textsubscript{2})) \\[5pt]
\quad\equiv\quad (11) \\[5pt]
\text{fun } \_ \rightarrow (k\ ())\ s\ [\text{x}/s, \text{fun } b \rightarrow \text{\textbf{with} nondet, state \textbf{handle}}(c.C\textsubscript{1})] \\[2pt]
 \text{++} \\ \text{fun } \_ \rightarrow (k\ ())\ s\ [\text{y}/s, \text{fun } d \rightarrow \text{\textbf{with} nondet, state \textbf{handle} }(e.C\textsubscript{2})] \\[5pt]

\end{array} 
\] 


\subsubsection{Deterministic Local State}
Within each branch, the state laws are predictable, the prior state laws hold.



\begin{tcolorbox}[colback=gray!10, colframe=gray!60, sharp corners, boxrule=0.5pt, title={POSIX Base Specifications, Issue 7, p.1339}]
If MAP\_PRIVATE is specified, modifications to the mapped data by the calling process shall be visible only to the 
calling process and shall not change the underlying object.
 \\ ...
A process is an address space with one or more threads executing within that address space. Each process has its own private memory and system resources
 \end{tcolorbox}




\vspace{-0.0em}
\[
\begin{array}{@{}l@{}l@{}l@{}l@{}}
\shortstack{
  \textbf{with } \text{nondet handle} \\
  \textbf{with } \text{state handle} \\
  \quad\quad\text{set(a)(x.set(b)(y.C))}
}
&
\shortstack{
  \textbf{with } \text{nondet handle} \\
  \textbf{with } \text{state handle} \\
  \quad\quad\text{set(a)(x.get()(y.C))}
}
&
\shortstack{
  \textbf{with } \text{nondet handle} \\
  \textbf{with } \text{state handle} \\
  \quad\quad\text{get()(x.set(b)(y.C))}
}
&
\shortstack{
  \textbf{with } \text{nondet handle} \\
  \textbf{with } \text{state handle} \\
  \quad\quad\text{get()(x.get()(y.C))}
}
\end{array}
\]

    \subsubsection{Impermanence} 
    Once a branch terminates its state modifications are no longer stored.



\begin{tcolorbox}[colback=gray!10, colframe=gray!60, sharp corners, boxrule=0.5pt, title={POSIX Base Specifications, Issue 7, p.554}]
Memory mappings that were created in the process shall be unmapped before the process
 is destroyed.
 \end{tcolorbox}
 

\[
\begin{array}{l}
\textbf{with } \text{nondet handle} \\
\quad \textbf{with } \text{state handle} \\
\quad\quad \text{set}(a)(x. \text{return } 0) \, \text{++} \, \text{set}(b)(y. \text{return } 0) \\[5pt]

\quad\equiv\quad (11) \\[5pt]

\textbf{with } \text{nondet handle} \\
\quad \text{fun } \_ \rightarrow (k())s \, [a/s, \text{fun } y \rightarrow \textbf{with } \text{state handle } \text{return } 0] \\
\quad\quad \text{++} \\
\quad \text{fun } \_ \rightarrow (k())s \, [b/s, \text{fun } y \rightarrow \textbf{with } \text{state handle } \text{return } 0] \\[5pt]

\quad\equiv\quad (\text{subst}) \\[5pt]
\textbf{with } \text{nondet handle} \\

\quad\text{fun } \_ \rightarrow (\text{fun } y \rightarrow \textbf{with } \text{state handle } \quad\text{return } 0)() \, a \\
\quad\quad \text{++} \\
\quad\text{fun } \_ \rightarrow (\text{fun } y \rightarrow \textbf{with } \text{state handle } \text{return } 0)() \, b \\[5pt]

\quad\equiv\quad (8) \\[5pt]

\textbf{with } \text{nondet handle} \\
\quad\text{fun } \_ \rightarrow (\textbf{with } \text{state handle } \text{return } 0) \, a \\
\quad\quad \text{++} \\
\quad\text{fun } \_ \rightarrow (\textbf{with } \text{state handle } \text{return } 0) \, b \\[5pt]

\quad\equiv\quad (10) \\[5pt]

\textbf{with } \text{nondet handle} \\
\quad\text{fun } \_ \rightarrow 0 \, a \quad \text{++} \quad \text{fun } \_ \rightarrow 0 \, b \\[5pt]

\quad\equiv\quad (\text{apply}) \\[5pt]

\textbf{with } \text{nondet handle} \\
\quad 0 \text{ ++ } 0
\end{array}
\]

    
\subsubsection{State Inheritance (Copy-On-Write):} Each new non deterministic process inherits an exact copy of its parent’s state. Any subsequent changes are isolated to that new branch alone. This is known as Copy-On-Write semantics. EXAMPLE of ENV

\begin{tcolorbox}[colback=gray!10, colframe=gray!60, sharp corners, boxrule=0.5pt, title={POSIX Base Specifications, Issue 7, p.897}]
Memory mappings created in the parent shall be retained in the child process
\end{tcolorbox}


\begin{tcolorbox}[examplebox, title=Practical Example: Inheriting environment variables]

\begin{lstlisting}
sessionmgr(Root, {
  if Fork() then {
    su(Alice);
    whoami();      // prints "Alice"
  } else {
    whoami();      // prints "Root"
  })
});
\end{lstlisting}

\[
\begin{array}{l}
\textbf{with } \mathit{nondet} \textbf{ handle } \\
\quad \textbf{with } \mathit{sessionmgr(Root)} \textbf{ handle } \\
\quad\quad \text{Fork}()(r. \textbf{if } r \textbf{ then } (su; \textit{whoami}()) \textbf{ else } \textit{whoami}()) \\[5pt]
\quad\equiv\quad (12) \\
\end{array}
\]

\[
\begin{array}{l}
\textbf{with } \mathit{nondet} \textbf{ handle } \textbf{Fork}()(r \mapsto \textbf{with } \mathit{sessionmgr} \textbf{ handle } (\textbf{if } r \ \textbf{then } (su; \mathit{whoami}()\\) \ \textbf{else } \mathit{whoami}())) \\[5pt]

\quad\equiv\quad (11) \\[2pt]
\textbf{resume } \mathit{true} \ \text{++} \ \textbf{resume } \mathit{false} \ [ ()/x,\ \textbf{fun } r \rightarrow \textbf{with } \mathit{sessionmgr} \textbf{ handle } (\textbf{if } r \ \\ \textbf{then } (su; \mathit{whoami}()) \ \textbf{else } \mathit{whoami}()) / k ] \\[5pt]

\quad\equiv\quad (\text{subst}) \\[2pt]
\textbf{fun } r \rightarrow \textbf{with } \mathit{sessionmgr} \textbf{ handle } (\textbf{if } r \ \textbf{then } (su; \mathit{whoami}()) \ \textbf{else } \mathit{whoami}()) \ \mathit{true} \\[2pt]
\text{++} \\[2pt]
\textbf{fun } r \rightarrow \textbf{with } \mathit{sessionmgr} \textbf{ handle } (\textbf{if } r \ \textbf{then } (su; \mathit{whoami}()) \ \textbf{else } \mathit{whoami}()) \ \mathit{false} \\[5pt]

\quad\equiv\quad (8) \\[2pt]
\textbf{with } \mathit{sessionmgr} \textbf{ handle } (su("Alice");\ \mathit{whoami}()) \\[2pt]
\text{++} \\[2pt]
\textbf{with } \mathit{sessionmgr("Root")} \textbf{ handle } \mathit{whoami}() \\[5pt]

\quad\equiv\quad (11) \\[2pt]
\textbf{env}(x,k)\ [\text{``Alice''}/x,\ \textbf{fun } y \rightarrow \textbf{with } \mathit{sessionmgr} \textbf{ handle } \mathit{whoami}()/k] \\[2pt]
\text{++} \\[2pt]
z \leftarrow \textbf{do Ask()} \ [()/x,\ \textbf{fun } z \rightarrow \textbf{with } \mathit{env} \textbf{ handle } C/k] \\
\end{array}
\]


\end{tcolorbox}







\subsection{Emergent Algebraic Behaviour}
Having clarified how the two handler orders meet the specifications for local and global state in Unix, we now examine the emergent algebraic properties of state, properties arising naturally but not explicitly designed for. This gives us deeper insights about how handler order affects state semantics. In this section we formally characterise and prove several of these key algebraic distinctions. 

\subsubsection*{Local State Breaks Associativity}
\begin{table}[H]
\centering
\begin{tabular}{p{0.45\textwidth} c p{0.45\textwidth}}
\begin{lstlisting}
if Fork(){
    // A
    if Fork(){
        // A continued
        pass
    }
    else{
        // C
    }
}
else{
    set("B")
}
\end{lstlisting}
&
&
\begin{lstlisting}
if Fork(){
    A
} 
else{
    // B
    set("B");
    if Fork(){
        // B continued
        pass
    }
    else{
        // C
        C
    }
}
\end{lstlisting}
\end{tabular}
\end{table}
\vspace{-2em}


\subsubsection*{Local State Full Distributivity}
Whilst left distributivity does not hold in general, it does hold in the special case of idempotent effects, where repeated applications of R are equivalent to applying it once. As right distributivity holds trivially through algebraicity of sequencing Local State is fully distributive 

\vspace{-2em}
\begin{table}[H]
\centering
\begin{tabular}{p{0.45\textwidth} c p{0.45\textwidth}}
\begin{lstlisting}
set(x);
if Fork(){
    P;
}
else{
    Q;
}
\end{lstlisting}
&
&
\begin{lstlisting}
if Fork(){
    set(x); 
    P;
}
else{ 
    set(x); 
    Q;
}
\end{lstlisting}
\end{tabular}
\end{table}
\vspace{-2em}

\section{Exceptions}
Processes can terminate successfully by running to completion, or they can terminate by performing an exit system call. The exit call takes a numeric argument indicating the exit status of the process. Unlike other operations exit does not allow for continuation, it discards the remaining computation and terminates execution immediately.

Exceptions disrupt all of the algebraic properties that held before hand, these properties now only hold on the assumption that there is no exception in their scope. Exceptions only hold one property, that any code that succeeds them is semantically irrelevant.


\effectDef{exit n}{\text{Exit : Int} \rightarrow 0}

\[
\mathrm{status} \;\overset{\mathrm{def}}{=}\;
\mathrm{handler} \;\left\{
\begin{array}{ll}
  \mathrm{\textbf{return}\:\_} & \mapsto 0 \quad\\[0.5ex]
  \langle\!\langle \mathrm{Ask} \langle\rangle\rangle &  \mapsto n \quad\\[0.5ex]
 
\end{array}
\right\}
\]







\subsection*{Absorption}

The absorption property states that once an exit operation is called within a computation, any further computation is irrelevant. The following formalises the property that, whatever comes after the exit, does not affect the behaviour of the program:

\equivalenceStatement{status}{Exit (n)(y.C)}{status}{Exit(n)(y.D)}

Because Exit n returns type 0, the uninhabited type, it cannot yield a result. To embed it in a computation expecting a value of type $\alpha$, we use the absurd function to coerce from the empty type to $\alpha$. This reflects that any code after Exit n is unreachable, and ensures the expression remains well-typed.






\[
\mathrm{exit\:n} \;\overset{\mathrm{def}}{=}\;
\mathrm{handler} \;\left\{
\begin{array}{l}
  \text{absurd\:(\textbf{do}\:Exit\:n)} \quad\\[0.5ex]

\end{array}
\right\}
\]



\underline{Left Hand Side}

\[
\begin{array}{l}
\quad\equiv\quad (\text{subst}) \\[5pt]
\text{absurd (do Exit } n) (y. C) \\[5pt]
\quad\equiv\quad (11) \\[5pt]
v [n/v, \text{fun } y \rightarrow \text{\textbf{with} status \textbf{handle} } C/k] \\[5pt]
\quad\equiv\quad (\text{subst}) \\[5pt]
n
\end{array}
\]

\underline{Right Hand Side}

\[
\begin{array}{l}
\quad\equiv\quad (11) \\[5pt]
\text{absurd (do Exit } n) (y. D) \\[5pt]
\quad\equiv\quad (11) \\[5pt]
v [n/v, \text{fun } y \rightarrow \text{\textbf{with} status \textbf{handle} } D/k] \\[5pt]
\quad\equiv\quad (\text{subst}) \\[5pt]
n
\end{array}
\]


\section{Process Synchronisation}

So far we have introduced a basic time-sharing, using interrupts and the scheduler, that allows the interleaving of process execution. However, as mentioned before, the way that processes are interleaved is non-deterministic, in other words processes don't know the order in which the will be executed. 

This is a problem because, as we have demonstrated, many of our effects are non-commutative meaning that the order of execution is important for correctness. This creates what is known as a "race condition", A race condition arises when the correctness of a program depends on the nondeterministic interleaving of concurrent operations on shared state. Without explicit synchronisation, the outcome is unpredictable and may differ across runs, making correct behaviour accidental rather than guaranteed.

Currently the only way to guarantee execution order is to execute all the steps, in the same process, sequentially with no interrupts which defeats the point of our time sharing system as no interleaving is possible in this time, which blocks the other processes.

To introduce flexibility around process interleaving whilst maintaining guarantees about execution ordering we introduce two features

\begin{itemize}
    \item \lstinline{Wait} \textbf{system calls: } This allows a parent to suspend execution until its child process (identified by its process id) has finished executing. Think of this as introducing a causal dependency, the parent can only when the child finishes.
    \item \textbf{Mutexes: } This a process to lock a resource, meaning that whilst the process holds this lock, no other process can alter this resource. This guarantees that between interrupts other processes don't alter the resource, which could potentially lead to file corruption. 
\end{itemize}

Combining these two properties by;
\begin{enumerate}
    \item Locking the resource, to prevent other processes simultaneously writing to (and thereby corrupting) our resource
    \item Splitting up the responsibility for writes between its children, and waiting in order for them to complete
    \item Unlocking the resource to allow other processes to access it
\end{enumerate}

we can provide guarantees about write safety whilst still allowing for concurrency.
 

\underline{Scenario 1} 
The 

\[
\mathrm{scheduler} \;\overset{\mathrm{def}}{=}\;
\textbf{handler} \;\left\{
\begin{array}{ll}
  \mathbf{return}\; x 
    & \mapsto \textbf{let } \mathrm{done'} \leftarrow (\mathrm{st.pid}, x) :: \mathrm{st.done} \textbf{ in} \\
    & \quad\quad \textbf{let } \mathrm{pcb'} = \mathrm{st.pcbMap.remove}(\mathrm{st.pid}) \textbf{ in} \\
    & \quad\quad \mathrm{runNext} \langle \mathrm{st\; with\; done = done';\; pcbMap = pcb'} \rangle
    
    \\[1ex]

  \langle\!\langle \mathrm{UFork} \langle\rangle \rangle\!\rangle 
    & \mapsto \textbf{let } \mathrm{resume'} \leftarrow \lambda\, \mathrm{st}.\; \mathrm{resume}(\langle 0,\; \mathrm{st} \rangle) \textbf{ in} \\
    & \quad\quad \textbf{let } \mathrm{pid} \leftarrow \mathrm{st.pnext} \textbf{ in} \\
    & \quad\quad \textbf{let } q' = \mathrm{st.q} \mathbin{++} [\langle \mathrm{pid};\; \mathrm{Ready}\; \mathrm{resume'} \rangle] \textbf{ in} \\
    & \quad\quad \textbf{let } \mathrm{pcb'} = \mathrm{st.pcbMap.insert}(\mathrm{pid},\; \mathrm{st.pid}) \textbf{ in} \\
    & \quad\quad \textbf{let } \mathrm{st'} = \langle \mathrm{st\; with\; q = q';\; pnext = pid} + 1;\; \\ 
    & \quad\quad\mathrm{pcbMap = pcb'} \rangle \textbf{ in} \\
    & \quad\quad \mathrm{resume}(\langle \mathrm{pid},\; \mathrm{st'} \rangle) \\[1ex]

  \langle\!\langle \mathrm{Wait} \langle pid \rangle \rangle\!\rangle 
    & \mapsto \textbf{if } \mathrm{st.pcbMap}[pid] \neq \mathrm{st.pid} \\
    & \quad\quad  \mathrm{resume}(-1,\; \mathrm{st}) \\[0.5ex]
    & \quad \textbf{else if } \mathrm{has}(pid,\; \mathrm{st.q}) \\
    & \quad\quad \textbf{let } \mathrm{resume'} \leftarrow \lambda\, \mathrm{st}.\; \mathrm{resume}(\langle\langle\rangle,\; \mathrm{st}) \textbf{ in} \\
    & \quad\quad \textbf{let } q' = \mathrm{st.q} \mathbin{++} [\langle \mathrm{st.pid};\; \mathrm{Blocked}\; \langle pid,\; \mathrm{resume'} \rangle \rangle]  \\
    & \quad\quad\textbf{in } \mathrm{runNext} \langle \mathrm{st\; with\; q = q'} \rangle \\[0.5ex]
    & \quad \textbf{else } \\ 
    & \quad\quad\mathrm{resume}(pid,\; \mathrm{st}) 
    \\
    

  \langle\!\langle \mathrm{Interrupt} \langle\rangle \rangle\!\rangle 
    & \mapsto \textbf{let } \mathrm{resume'} \leftarrow \lambda\, \mathrm{st}.\; \mathrm{resume}(\langle\langle\rangle,\; \mathrm{st}) \textbf{ in} \\
    & \quad\quad \textbf{let } q' = \mathrm{st.q} \mathbin{++} [\langle \mathrm{st.pid};\; \mathrm{Ready}\; \mathrm{resume'} \rangle] \textbf{ in} \\
    & \quad\quad \mathrm{runNext} \langle \mathrm{st\; with\; q = q'} \rangle
\end{array}
\right\}
\]

Reasoning about the scheduler is very difficult because it introduces non-determinism into our system. Unlike the algebraic effects, which have clear equational rules, the behaviour of the scheduler depends on the runtime state of the process queue and the particular order in which processes are resumed. 





\subsection*{How Wait Distributes Over Fork}


This proof shows how \texttt{wait} interacts with \texttt{fork}. Both resumptions produced by the \texttt{pid\_nondet} handler perform a \texttt{wait}. In the parent process, \texttt{wait(pid)} refers to the child and corresponds to a standard blocking operation. In the child process, \texttt{Fork()} returns \texttt{0} to indicate that it is the newly created process. Since there is no process with PID \texttt{0} in the queue, \texttt{wait(0)} has no effect and acts as a no-op, returning \texttt{()}.









\[
\mathrm{pid\_nondet} \;\overset{\mathrm{def}}{=}\;
\textbf{handler} \;\left\{
\begin{array}{ll}
  \mathrm{\textbf{return}\:res} & \mapsto [res] \quad\\[0.5ex]
  \langle\!\langle \mathrm{Fork} \langle\rangle\rangle &  \mapsto \textbf{resume} \text{ 0 ++ \textbf{resume} get\_fresh\_pid()}     \quad\\[0.5ex]
  
\end{array}
\right\}
\]

\[
\mathrm{parentChildMap} \;\overset{\mathrm{def}}{=}\; \textbf{handler}
\left\{
\begin{array}{ll}
\mathbf{return}\; x 
  & \mapsto x \\[1ex]

\langle\!\langle \mathrm{get}(k) \rangle\!\rangle 
  & \mapsto \textbf{let } v \leftarrow \mathrm{map}[k] \textbf{ in} \\
  & \quad \mathrm{resume}(v,\; \mathrm{map}) \\[1ex]

\langle\!\langle \mathrm{put}(k, v) \rangle\!\rangle 
  & \mapsto \textbf{let } \mathrm{map'} \leftarrow \mathrm{map}[k := v] \textbf{ in} \\
  & \quad \mathrm{resume}(\langle\langle\rangle,\; \mathrm{map'})
\end{array}
\right\}
=\]


\[
\mathrm{waitHandler} \;\overset{\mathrm{def}}{=}\; \textbf{handler}
\left\{
\begin{array}{ll}
\mathbf{return}\; x 
  & \mapsto x \\[1ex]

\langle\!\langle \mathrm{Wait}(pid) \rangle\!\rangle 
  & \mapsto \textbf{let } \mathrm{parent} \leftarrow \mathrm{get}(pid) \textbf{ in} \\
  & \quad \textbf{if } \mathrm{parent} \neq \mathrm{st.current\_pid} \\ & \quad\quad  \mathrm{resume}(-1) \\[0.5ex]
  & \quad \textbf{else if } \mathrm{has}(pid,\; \mathrm{st.q})  \\
  & \quad\quad \text{// block process and add to back of queue} \\
  & \quad \textbf{else } \\ & \quad\quad \mathrm{resume}(pid)
\end{array}
\right\}
\]



\[
\begin{array}{l}
\textbf{with } \mathit{parentChildMap} \textbf{ handle } \\
\quad\textbf{with } \mathit{pid\_nondet} \textbf{ handle } \\
\quad\quad \text{Fork}()(r. \text{Wait(r)(p.} \textbf{if } r  \textbf{ then } \text{C1} \textbf{ else } \text{C2)} \\[5pt]
\equiv \\
\textbf{with } \mathit{parentChildMap} \textbf{ handle } \\
\quad\textbf{with } \mathit{pid\_nondet} \textbf{ handle } \\\quad\quad \text{Fork}()(r. \textbf{if } r 
\textbf{ then } (\textit{Wait(p)(p.C1)} \textbf{ else } \text{C2)} \\[5pt]

\end{array}
\]




\vspace{-2em}
\begin{table}[H]
\centering
\begin{tabular}{p{0.45\textwidth} c p{0.45\textwidth}}
\begin{lstlisting}
p = Fork();
Wait(p);
if p
    C1
else
    C2
\end{lstlisting}
&
&
\begin{lstlisting}
p = Fork();
if p
    Wait(p);
    C1
else
    C2
\end{lstlisting}
\end{tabular}
\end{table}
\vspace{-2em}

\underline{Proof}

\underline{Left Hand Side}
\[
\begin{array}{l}
Fork ()(y.\ \text{Wait}(y)(z.\ \textbf{if } y\ \textbf{then } C_1\ \textbf{else } C_2)) \\[5pt]

\quad\equiv\quad (11) \\[2pt]
\textbf{resume } 0\ \text{++}\ \textbf{resume } \mathit{pid} \ [()/v,\ \textbf{fun } y \rightarrow \textbf{with } \mathit{pid\_nondet} \ \textbf{handle } \text{Wait}(y)(z.\ \textbf{if } y\ \textbf{then } C_1\ \textbf{else } C_2)\ /\ \textbf{resume} ] \\[5pt]

\quad\equiv\quad (\text{subst}) \\[2pt]
\textbf{fun } y \rightarrow \textbf{with } \mathit{pid\_nondet} \ \textbf{handle } \text{Wait}(y)(z.\ \textbf{if } y\ \textbf{then } C_1\ \textbf{else } C_2)\ 0 \\[2pt]
\text{++} \\[2pt]
\textbf{fun } y \rightarrow \textbf{with } \mathit{pid\_nondet} \ \textbf{handle } \text{Wait}(y)(z.\ \textbf{if } y\ \textbf{then } C_1\ \textbf{else } C_2)\ \mathit{pid} \\[5pt]

\quad\equiv\quad (\text{application}) \\[2pt]
\textbf{with } \mathit{pid\_nondet} \ \textbf{handle } \text{Wait}(0)(z.\ \textbf{if } 0\ \textbf{then } C_1\ \textbf{else } C_2) \\[2pt]
\text{++} \\[2pt]
\textbf{with } \mathit{pid\_nondet} \ \textbf{handle } \text{Wait}(\mathit{pid})(z.\ \textbf{if } \mathit{pid}\ \textbf{then } C_1\ \textbf{else } C_2) \\[5pt]

\quad\equiv\quad (5,6) \\[2pt]
\textbf{with } \mathit{pid\_nondet} \ \textbf{handle } \text{Wait}(0)(z.\ C_2)\ \text{++}\ \textbf{with } \mathit{pid\_nondet} \ \textbf{handle } \text{Wait}(\mathit{pid})(z.\ C_1) \\[5pt]
\end{array} 
\]


\underline{Right Hand Side}
\[
\begin{array}{l}
\textbf{with } \mathit{pid\_nondet} \textbf{ handle } \textbf{Fork}()(y.\ \textbf{if } y \ \textbf{then } \text{Wait}(y)(z.C_1)\ \textbf{else } C_2) \\[5pt]

\quad\equiv\quad (11) \\[2pt]
\textbf{resume } 0\ \text{++}\ \textbf{resume } \mathit{pid} \ [()/v,\ \textbf{fun } y \rightarrow \textbf{with } \mathit{pid\_nondet} \textbf{ handle } \textbf{if } y \ \textbf{then } \text{Wait}(y)(z.C_1)\  \textbf{else } C_2\ /\ \textbf{resume} ] \\[5pt]

\quad\equiv\quad (\text{subst}) \\[2pt]
\textbf{fun } y \rightarrow \textbf{with } \mathit{pid\_nondet} \textbf{ handle } \textbf{if } y \ \textbf{then } \text{Wait}(y)(z.C_1)\ \textbf{else } C_2\  \ 0 \\[2pt]
\text{++} \\[2pt]
\textbf{fun } y \rightarrow \textbf{with } \mathit{pid\_nondet} \textbf{ handle } \textbf{if } y \ \textbf{then } \text{Wait}(y)(z.C_1)\ \textbf{else } C_2\ \mathit{pid} \\[5pt]

\quad\equiv\quad (\text{application}) \\[2pt]
\textbf{with } \mathit{pid\_nondet} \textbf{ handle } \textbf{if } 0 \ \textbf{then } \text{Wait}(0)(z.C_1) \ \textbf{else } C_2 \\[2pt]
\text{++} \\[2pt]
\textbf{with } \mathit{pid\_nondet} \textbf{ handle } \textbf{if } \mathit{pid} \ \textbf{then } \text{Wait}(\mathit{pid})(z.C_1)\ \textbf{else } C_2 \\[5pt]

\quad\equiv\quad (5,6) \\[2pt]
\textbf{with } \mathit{pid\_nondet} \textbf{ handle } C_2\ \text{++}\ \textbf{with } \mathit{pid\_nondet} \textbf{ handle } \text{Wait}(\mathit{pid})(z.C_1) \\[5pt]
\end{array}
\]

\section{Reasoning Conclusions}

In this section we have demonstrated how to use algebraic equivalences to reason about effect handlers. We first examined different models of state depending on how we composed the nondeterminism and state handlers, which corresponded to global file system state and process local state. We verified that each of these models fulfilled the properties that Unix expected them to have. 

We then went on to reason about other interesting properties that the equivalences allowed us to show. This helped to verify that certain program transformations are valid and allowed us to simplify our code. 

We also discovered that many of the rules that held in an isolated setting break down under composition. 

It is very difficult to reason about any properties which rely on the scheduler. This makes reasoning about any forms of process synchronsiation or interprocess communication very difficult to do. Unfortunately effects like \lstinline{Wait} or \lstinline{Acquire} \lstinline{Release} which introduce partial order semantics can't be easily reasoned about using our equivalences as they depend upon the dynamic execution state of our system.

\chapter{Conclusions}

\section{Unix Implementation in Koka}
We have successfully realised the "Toy Unix" system described in Hillerström's paper, we provided implementations for exception handling, a basic IO scheme, user functionality, a basic serial file system, piping and two methods of process scheduling. We achieved the goal we set out to do namely, to show that we can implement a simulation of Unix, tackling the complex problems this presents, in a concise and modular way.

\subsection*{Future Work}
Implementing the process synchronisation features described in the previous chapter would provide vital functionality to our Unix system. Currently, if the system wants to perform writes in order, it can't do any interleaving, meaning that all writes are blocking defeating the purpose of a time-sharing system. Mutexes would provide a simple way to guarantee that resources can't be tampered with.

\section{Reasoning}
We successfully verified that our implementation of Unix follows the rules expected of it according to the Unix Specifications. We quickly ran into problems when trying to reason about anything which was not directly related to code structure, the dynamic state of the scheduler prevented us doing any reasoning about synchronisation or IPC.
\subsection*{Future}
Further reasoning about partial ordering of effectful operations using Waits and Mutexes. We could also implement a model of Local File Descriptor tables for processes and a global Open File Table. This would open up reasoning about sharing and isolation of state and how this aids modularity and functionality.  

% \bibliographystyle{plain}
\bibliographystyle{plain}
\bibliography{mybibfile}


% You may delete everything from \appendix up to \end{document} if you don't need it.
\appendix

\chapter{First appendix}

\section{First section}

Any appendices, including any required ethics information, should be included
after the references.

Markers do not have to consider appendices. Make sure that your contributions
are made clear in the main body of the dissertation (within the page limit).

\chapter{Participants' information sheet}

If you had human participants, include key information that they were given in
an appendix, and point to it from the ethics declaration.

\chapter{Participants' consent form}

If you had human participants, include information about how consent was
gathered in an appendix, and point to it from the ethics declaration.
This information is often a copy of a consent form.


\end{document}
